{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Euler Method (first derivation)\n",
    "In the last lecture, we used a first order forward difference scheme to approximate the derivative $\\dot{x}$ in our initial value problem \n",
    "\n",
    "$\\dot{x}(t) = f(t, x(t))$ and $x(0) = x_0.\\hspace{1in}$ (1)\n",
    "\n",
    "There is no obvious reason why we had to use a forward difference scheme.  For example, we could just as easily have used the first order backward difference scheme\n",
    "\n",
    "$\\dot{x}(t) \\approx \\frac{x(t) - x(t - \\Delta t)}{\\Delta t}$.  \n",
    "\n",
    "This approximation is valid at any time, so in particular it is valid at time $t_1$.  We therefore have \n",
    "\n",
    "$\\dot{x}(t_1) \\approx \\frac{x(t_1) - x(t_1 - \\Delta t)}{\\Delta t} = \\frac{x(t_1) - x(t_0)}{\\Delta t}$.  \n",
    "\n",
    "If we use this approximation in our differential equation (at time $t_1$), then we get \n",
    "\n",
    "$\\frac{x(t_1) - x(t_0)}{\\Delta t} \\approx f(t_1, x(t_1))$.  \n",
    "\n",
    "We know from the initial condition that $x(t_0) = x_0$.  If we plug this in and do a little simplifying, we get \n",
    "\n",
    "$x(t_1) \\approx x_0 + \\Delta t f(t_1, x(t_1))$.  \n",
    "\n",
    "Of course, we still don't know what $x(t_1)$ is, but we can use this formula as the definition of our approximation $x_1$: \n",
    "\n",
    "$x_1 = x_0 + \\Delta t f(t_1, x_1)$.  \n",
    "\n",
    "This looks almost the same as our formula for the forward Euler method, but there is one very important difference.  This function is not actually solved for $x_1$ because there is still an $x_1$ on the right hand side.  We say that this is an *implicit* equation for $x_1$ because we still need to do more work to solve for our next approximation.  In principle, if we know the formula for $f$ (which we always will - it is just the right hand side of our differential equation) then we can solve this equation for $x_1$.  However, it might be very difficult, or even impossible, to solve the equation by hand.  Fortunately, there are many numerical methods (including some builtin python functions) that we can use to solve the equation.  In this lecture, we will just assume that we have solved for $x_1$ and not worry about how to actually do so.  \n",
    "\n",
    "Just like in the last lecture, we can repeat this process with time $t_2$ instead of $t_1$.  We get the approximation \n",
    "\n",
    "$\\frac{x(t_2) - x(t_2 - \\Delta t)}{\\Delta t} \\approx f(t_2, x(t_2))$.  \n",
    "\n",
    "If we simplify this (and use the fact that the $t$'s are evenly spaced) we get \n",
    "\n",
    "$x(t_2) \\approx x(t_1) + \\Delta t f(t_2, x(t_2))$.  \n",
    "\n",
    "We don't know $x(t_1)$ or $x(t_2)$, but we do already have a good approximation for $x(t_1)$, so we can write \n",
    "\n",
    "$x(t_2) \\approx x_1 + \\Delta t f(t_2, x(t_2))$.  \n",
    "\n",
    "We will now take this as a definition for the approximation $x_2$, so we have \n",
    "\n",
    "$x_2 = x_1 + \\Delta t f(t_2, x_2)$.  \n",
    "\n",
    "Once again, this formula isn't actually solved for $x_2$ yet, but at least in principle we can solve it, so we will assume that we have found $x_2$.  \n",
    "\n",
    "We can repeat this process indefinitely.  In general, if we already have all the approximations for $x(t)$ up to $x_k$, then we get the formula \n",
    "\n",
    "$x_{k+1} = x_k + \\Delta t f(t_{k+1}, x_{k+1})$.  \n",
    "\n",
    "Again, this is an implicit equation for $x_{k+1}$.  If the formula for $f$ is relatively simple, then we might be able to find $x_{k+1}$ by hand, but usually we will have to use some python method to approximate the solution.  We call this method for approximating the $x$ values the *backward Euler method*.  It is a time stepping method, because we approximate $x$ at each time and turn and never go back to approximate $x$ at an earlier time again.  We say that the method is *implicit*, because at each step we have to solve an implicit equation for $x_{k+1}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Euler Method (second derivation)\n",
    "Just like with the forward Euler method, we can re-derive backward Euler in a second way.  We do this by taking the original differential equation \n",
    "\n",
    "$\\dot{x}(t) = f(t, x(t))$\n",
    "\n",
    "and integrating both sides from $t_k$ to $t_{k+1}$.  The left side is easy to do exactly (using the fundamental theorem of calculus) and we get \n",
    "\n",
    "$x(t_{k+1}) - x(t_k) = \\displaystyle\\int_{t_k}^{t_{k+1}}f(t, x(t))\\,\\textrm{d}t$.  \n",
    "\n",
    "We don't know the formula for $x(t)$, so we can't hope to integrate the right side exactly, but we can approximate this integral using any of the methods from last week.  In particular, if we use the right hand rule (with only one rectangle) then we get \n",
    "\n",
    "$x(t_{k+1}) - x(t_k) \\approx \\Delta t f(t_{k+1}, x(t_{k+1}))$, \n",
    "\n",
    "which we can rewrite as \n",
    "\n",
    "$x(t_{k+1}) \\approx x(t_k) + \\Delta t f(t_{k+1}, x(t_{k+1}))$.  \n",
    "\n",
    "We don't know either $x(t_k)$ or $x(t_{k+1})$, but we can use this formula as a definition for our approximations.  We therefore have \n",
    "\n",
    "$x_{k+1} = x_k + \\Delta t f(t_{k+1}, x_{k+1})$.  \n",
    "\n",
    "This is the same formula as what we got above, so we have just re-derived the backward Euler method in a different manner.  \n",
    "\n",
    "The advantage of this derivation is that it gives us an easy way to find the local and global accuracy of the backward Euler method.  The right hand rule has second order local error and first order global error and these results translate directly into accuracy for the backward Euler method.  We therefore know that backward Euler has a local accuracy of $\\mathcal{O}(\\Delta t^2)$ and a global accuracy of $\\mathcal{O}(\\Delta t)$.  Since we usually care more about global accuracy than local accuracy, we say that the backward Euler method is first order accurate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward vs Backward Euler\n",
    "Notice that both of the methods we have derived have the same accuracy (they are both first order).  The only real difference we can see so far is that forward Euler is explicit while backward Euler is implicit.  This means that it is very easy to solve for $x_{k+1}$ at every step in forward Euler (there's really no solving involved - just plugging in), but it might be quite difficult to find $x_{k+1}$ at each step in backward Euler.  In particular, the numerical methods for solving an implicit equation are usually iterative, so they take many steps.  This means that every step of backward Euler (that is, every time you want to find one more $x$ value) will usually take a lot longer than a corresponding step of forward Euler because we have to solve an implicit equation.  You might therefore wonder why we would ever use backward Euler.  The answer has to do with the concept of stability, which we briefly introduced in the last lecture.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability\n",
    "Remember that stability has to do with how our solution behaves if we make the final time $T$ very large.  This turns out to be a very complicated concept, and it often depends on the details of our differential equation, so we will only look at one of the simplest versions of stability.  In particular, we will only talk about stability in terms of a very simple family of differential equations: \n",
    "\n",
    "$\\dot{x} = \\lambda x$ and $x(0) = x_0$, \n",
    "\n",
    "where $\\lambda$ is a constant.  (It turns out that when we try to solve systems of equations we will need to worry about complex values of $\\lambda$, but for the moment we will just pretend that $\\lambda$ is real.)  This is called a *test problem*.  \n",
    "\n",
    "**Note:** I am trying to avoid more technical definitions of stability and some of the more complicated concepts from differential equations.  Unfortunately, this means that I am also using somewhat non-standard definitions of words like \"stable\" and \"unstable\".  If you are interested in the standard definitions, a good place to start is by looking up \"A-stability\".  \n",
    "\n",
    "We already saw in the previous lecture that the true solution to the test problem is \n",
    "\n",
    "$x(t) = x_0e^{\\lambda t}$.  \n",
    "\n",
    "We want to know what happens to this solution (and to our approximations, but let's start with the true solution) after a very long time.  In this case, there are only two possibilities.  If $\\lambda > 0$, then $x$ goes off to $\\pm\\infty$ as time goes on.  We will call the true solution \"unstable\" in this case.  If $\\lambda < 0$, then $x$ goes to zero as time goes on.  We will call the true solution \"stable\" in this case.  (Technically, there is a third possibility.  If $\\lambda = 0$, then $x(t)$ stays constant forever.  However, this is a pretty degenerate case, so we won't worry about it here.)\n",
    "\n",
    "Ideally, we want our numerical methods to capture this stable/unstable behavior.  That is, if we solve this initial value problem using something like the forward or backward Euler method, we want our approximation to go to infinity when $\\lambda > 0$ and to go to zero when $\\lambda < 0$.  Unfortunately, it turns out that this is not actually possible.  We will always have some tradeoff where our approximation goes to infinity even though the true solution does not, or vice versa.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of Forward Euler\n",
    "Let's look at what happens when we apply the forward Euler method to the test problem.  If we already know all of the $x$ values up to $x_k$, then we can find the next $x$ value using the equation \n",
    "\n",
    "$x_{k+1} = x_k + \\Delta t f(t_k, x_k)$.  \n",
    "\n",
    "In this case, $f(t, x) = \\lambda x$, so we have \n",
    "\n",
    "$x_{k+1} = x_k + \\Delta t \\lambda x_k = (1 + \\Delta t\\lambda)x_k$.  \n",
    "\n",
    "If we use this formula with $k = 0$, then we find \n",
    "\n",
    "$x_1 = (1 + \\Delta t\\lambda)x_0$.  \n",
    "\n",
    "Likewise, if we use $k = 1$ then we find \n",
    "\n",
    "$x_2 = (1 + \\Delta t\\lambda)x_1 = (1 + \\Delta t\\lambda)^2x_0$.  \n",
    "\n",
    "It is easy to check that if we repeat this process $k$ times we will get the general formula \n",
    "\n",
    "$x_k = (1 + \\Delta t\\lambda)^kx_0$.  \n",
    "\n",
    "From this equation we can see that our approximations $x_k$ go to $\\pm\\infty$ if $|1 + \\Delta t\\lambda| > 1$.  If this is the case then we say that forward Euler is \"unstable\".  Likewise, if $|1 + \\Delta t\\lambda| < 1$ then our approximations $x_k$ go to zero and we say that forward Euler is \"stable\".  \n",
    "\n",
    "It is very important to notice that this is not the same as the stability of the true solution.  The true solution is stable whenever $\\lambda$ is negative, but it is easy to come up with combinations of $\\Delta t$ and $\\lambda$ where $\\lambda$ is negative, but forward Euler is unstable.  For instance, if $\\Delta t = 1$ and $\\lambda = -10$, then $|1 + \\Delta t\\lambda| = 9 > 1$, so forward Euler is unstable even though the true solution is stable.  However, it is easy to check that if $\\lambda$ is positive then $|1 + \\Delta t\\lambda| > 1$, so if the true solution is unstable then so is the forward Euler approximation.  \n",
    "\n",
    "We therefore know that the forward Euler solution is unstable whenever the true solution is unstable, but sometimes forward Euler is not stable even though the true solution is stable.  In particular, if $-2 < \\Delta t\\lambda < 0$, then the forward Euler approximation will be stable, but if $\\Delta t\\lambda < -2$ then the forward Euler approximation will be unstable (even though the true solution is actually stable).  \n",
    "\n",
    "Notice that, for any fixed value of $\\lambda$, if we choose $\\Delta t$ small enough then the stability of our approximation will always match the stability of the true solution, but if $\\lambda$ is negative then we might need a very small $\\Delta t$ to make sure that forward Euler is stable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of Backward Euler\n",
    "Similarly, we can look at what happens when we apply the backward Euler method to the test problem.  If we already know all of the $x$ values up to $x_k$, then we can find the next $x$ value using the equation \n",
    "\n",
    "$x_{k+1} = x_k + \\Delta t f(t_{k+1}, x_{k+1})$.  \n",
    "\n",
    "In this case, $f(t, x) = \\lambda x$, so we have \n",
    "\n",
    "$x_{k+1} = x_k + \\Delta t\\lambda x_{k+1}$.  \n",
    "\n",
    "This is an implicit equation, but it is very easy to solve for $x_{k+1}$.  We get \n",
    "\n",
    "$x_{k+1} = \\frac{1}{1 - \\Delta t\\lambda}x_k$.  \n",
    "\n",
    "If we use this formula with $k = 0$, we find that \n",
    "\n",
    "$x_1 = \\frac{1}{1 - \\Delta t\\lambda}x_0$.  \n",
    "\n",
    "Likewise, if we use $k = 1$ then we find \n",
    "\n",
    "$x_2 = \\frac{1}{1 - \\Delta t\\lambda}x_1 = \\left(\\frac{1}{1 - \\Delta t\\lambda}\\right)^2x_0$.  \n",
    "\n",
    "It is easy to check that if we repeat this process $k$ times we will get the general formula \n",
    "\n",
    "$x_k = \\left(\\frac{1}{1 - \\Delta t\\lambda}\\right)^{k}x_0$.  \n",
    "\n",
    "From this equation we can see that our approximations $x_k$ go to $\\pm\\infty$ if $|1/(1 - \\Delta t\\lambda)| > 1$.  If this is the case then we say that backward Euler is \"unstable\".  Likewise, if $|1/(1 - \\Delta t\\lambda)| < 1$ then our approximations $x_k$ go to zero and we say that backward Euler is \"stable\".  \n",
    "\n",
    "Just like with forward Euler, it is very important to notice that this is not the same as the stability of the true solution (or as the rule for forward Euler).  In particular, if $\\lambda$ is positive then the true solution is always unstable, but it is easy to come up with combinations of $\\Delta t$ and $\\lambda$ where $\\lambda$ is positive but backward Euler is stable.  For example, if $\\Delta t = 1$ and $\\lambda = 10$, then $|1/(1 - \\Delta t\\lambda)| = 1/9 < 1$, so backward Euler is stable even though the true solution is unstable.  \n",
    "\n",
    "We therefore know that the backward Euler solution is stable whenever the true solution is stable, but sometimes backward Euler is still stable even though the true solution is unstable.  In particular, the backward Euler approximation is only unstable when $0 < \\Delta t\\lambda < 2$.  If $\\Delta t\\lambda > 2$ then backward Euler will be stable (even though the true solution is actually unstable).  \n",
    "\n",
    "For any fixed value of $\\lambda$, if we choose $\\Delta t$ small enough then the stability of our approximation will always match the stability of the true solution, but if $\\lambda$ is positive then we might need a very small $\\Delta t$ to make sure that the behavior of backward Euler matches that of the true solution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We only analyzed the stability of a very limited set of differential equations (the test problems) and we only looked at two methods (forward and backward Euler), but it turns out that this analysis applies to a wide variety of problems and methods.  More complicated differential equations don't usually just go to zero as time goes on, but we are still interested in correctly capturing whatever long term behavior they have.  We will say that the solution to a differential equation is \"stable\" if it does *not* go to infinity as time goes on.  (This is not a very good definition, but we would have to spend several classes on differential equations theory in order to make a substantially better one.)  It turns out that explicit approximation methods are prone to going to infinity even when the true solution is stable, while implicit methods are good at capturing stable behavior.  This means that explicit methods often need a fairly small time step $\\Delta t$ in order to correctly capture long-term stable behavior.  Implicit methods, on the other hand, can correctly capture long-term stable behavior even with a fairly large time step.  \n",
    "\n",
    "In real world applications, solutions rarely go to infinity.  For example, if we are modeling the population of a species, there are physical limits (like space or resource requirements) that keep this population from becoming infinitely large.  Because of this, we typically expect the true solution of our initial value problems to be stable.  This means that implicit methods like backward Euler can usually correctly capture long-term behavior with a larger time step than explicit methods like forward Euler.  We therefore say that implicit methods like backward Euler have \"better stability properties\" or are \"more stable\" than explicit methods.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
