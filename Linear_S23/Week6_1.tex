\documentclass[reqno]{amsart}


\pagestyle{empty}

\usepackage{graphicx}
\usepackage[margin = 1cm]{geometry}
\usepackage{color}
\usepackage{cancel}
\usepackage{multirow}
\usepackage{framed}
\usepackage{amssymb}
\usepackage{stackengine}

\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\newenvironment{handwave}{%
  \renewcommand{\proofname}{Handwavey proof}\proof}{\endproof}
  %\renewcommand{\qedsymbol}{$\blacksquare$}

\begin{document}
\begin{flushleft}
{\sc \Large AMATH 352 Rahman} \hfill Week 6
\bigskip
\end{flushleft}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\CancelColor}{\color{red}}
\newcommand{\?}{\stackrel{?}{=}}
\renewcommand{\varphi}{\phi}
\newcommand{\card}{\text{Card}}
\newcommand{\bigzero}{\text{\Huge 0}}
\newcommand{\curvearrowdown}{{\color{red}\rotatebox{90}{$\curvearrowleft$}}}
\newcommand{\curvearrowup}{{\color{red}\rotatebox{90}{$\curvearrowright$}}}



\section*{Sec. 2.3 and 2.4  Spanning sets and linear independence; basis and dimension.}

First we notice that $n$ vectors cannot be linearly independent in $\R^m$ if $n > m$.
Further, if we do not have enough vectors a linear combination will not be able to create
any other vector in the space.  Lets see what this means about the dimension of the space.

\begin{definition}
If a vector space $V$ consists of all linear combinations of $w_1,\ldots,w_n$, then these vectors \underline{span}
the space.  Every vector $v \in V$ is some combination of $w's$; i.e., $v = c_1w_1 + \cdots + c_nw_n$.
\end{definition}

For example
%
\begin{equation*}
w_1 = \begin{bmatrix}
1\\
0\\
0
\end{bmatrix},\quad w_2 = \begin{bmatrix}
0\\
1\\
0
\end{bmatrix},\quad w_3 = \begin{bmatrix}
-2\\
0\\
0
\end{bmatrix}
\end{equation*}
%
spans the $x-y$ plane in $\R^3$.  However, we notice that they are not linearly independent
since $w_3 = -2w_1$.

\begin{definition}
A basis for $V$ is a sequence of vectors having the following two properties:
%
\begin{enumerate}

\item  The vectors are linearly independent {\color{blue}(not too many vectors)}

\item  They span the space $V$ {\color{blue}(not too few vectors)}

\end{enumerate}
\end{definition}

We sketched this in the recording.  Make sure you understand that picture.

\begin{definition}
Any two bases for a vector space $V$ contains the same number of vectors.  This number, which is
shared by all bases and expresses the number of ``degrees of freedom'' of the space, is the
\underline{dimension} of $V$.
\end{definition}

This leads us to a coupe of theorems.

\begin{thm}
If $v_1,\ldots,v_m$ and $w_1,\ldots,w_n$ are both bases for the same vector space, then $m = n$.
\end{thm}

\begin{thm}
Any linearly independent set in $V$ can be extended to a basis, by adding more vectors if necessary.

Any spanning set in $V$ can be reduced to a basis, by discarding vectors if necessary.
\end{thm}

\bigskip
\bigskip

Now lets look at some examples.

\begin{enumerate}

\item[Ex:  ]  Write each vector as a linear combination of vectors in
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
2\\
-1\\
3
\end{bmatrix}, \begin{bmatrix}
5\\
0\\
4
\end{bmatrix}\right\rbrace
\end{equation*}

\begin{enumerate}

\item[a)]
%
\begin{equation*}
z = \begin{bmatrix}
-1\\
-2\\
2
\end{bmatrix}
\end{equation*}

\begin{equation*}
c_1s_1 + c_2s_2 = 
c_1\begin{bmatrix}
2\\
-1\\
3
\end{bmatrix} + c_2\begin{bmatrix}
5\\
0\\
4
\end{bmatrix} = \begin{bmatrix}
2c_1 + 5c_2\\
-c_1 + 0\\
3c_1 + 4c_2
\end{bmatrix} \? \begin{bmatrix}
-1\\
-2\\
2
\end{bmatrix} = z.
\end{equation*}
%
This gives us $c_1 = 2$, $c_2 = -1$ and the other equation is satisfied.  So,
%
\begin{equation*}
z = 2\begin{bmatrix}
2\\
-1\\
3
\end{bmatrix} - \begin{bmatrix}
5\\
0\\
4
\end{bmatrix}
\end{equation*}

\item[b)  ]  
%
\begin{equation*}
w = \begin{vmatrix}
1\\
-8\\
12
\end{vmatrix}
\end{equation*}

We can just use the vector addition from the previous problem,
%
\begin{equation*}
\begin{bmatrix}
2c_1 + 5c_2\\
-c_1 + 0\\
3c_1 + 4c_2
\end{bmatrix} \? \begin{bmatrix}
1\\
-8\\
12
\end{bmatrix}
\end{equation*}
%
Then $c_1 = 8$, $c_2 = -3$, and the other equation is satisfied, so
%
\begin{equation*}
w = 8\begin{bmatrix}
2\\
-1\\
3
\end{bmatrix} - 3\begin{bmatrix}
5\\
0\\
4
\end{bmatrix}
\end{equation*}

\item[c)  ]  
%
\begin{equation*}
u = \begin{vmatrix}
1\\
1\\
-1
\end{vmatrix}
\end{equation*}

We do the same as the last two

\begin{equation*}
\begin{bmatrix}
2c_1 + 5c_2\\
-c_1 + 0\\
3c_1 + 4c_2
\end{bmatrix} \? \begin{bmatrix}
1\\
1\\
-1
\end{bmatrix}
\end{equation*}
%
Then plugging into the second equation gives us $c_1 = -1$, and the first gives $c_2 = 3/5$, but
$3c_1 + 4c_2 \neq 1$, so we cannot write $u$ as a linear combination of the vectors in $S$.

\end{enumerate}

\item[Ex:  ]  Does the set of vectors
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
2\\
1
\end{bmatrix},\begin{bmatrix}
-1\\
2
\end{bmatrix}\right\rbrace
\end{equation*}
%
span $\R^2$.  {\color{blue}(we sketched this in the recording)}

\textbf{Solution}:  This is only one way to show that the vectors span a space, but it is
a convenient technique to use for this type of example.

If the vectors span the space, then any vector in the space can be represented as a linear
combination of the vectors in the set; i.e.,
%
\begin{equation*}
c_1s_1 + c_2s_2 = c_1\begin{bmatrix}
2\\
1
\end{bmatrix} + c_2\begin{bmatrix}
-1\\
2
\end{bmatrix} = \begin{bmatrix}
2c_1 - c_2\\
c_1 + 2c_2
\end{bmatrix}  \? \begin{bmatrix}
x\\
y
\end{bmatrix}
\end{equation*}
%
Notice that this is just a system of equations where $x$ and $y$ are fixed.
%
\begin{equation*}
\begin{cases}
2c_1 - c_2 &= x\\
c_1 + 2c_2 &= y
\end{cases} \Rightarrow \begin{bmatrix}
2 & -1\\
1 & 2
\end{bmatrix}\begin{bmatrix}
c_1\\
c_2
\end{bmatrix} = \begin{bmatrix}
x\\
y
\end{bmatrix}
\end{equation*}
%
So the question we want to ask is, ``does this system have a solution''?  Recall that if the
matrix is non-singular that system will have a unique solution.  Further, recall, that this
can be shown by just taking the determinant
%
\begin{equation*}
\begin{vmatrix}
2 & -1\\
1 & 2
\end{vmatrix} = 5 \neq 0,
\end{equation*}
%
so the matrix is nonsingular, hence the system of equations does have a solution, and therefore
the vectors span $\R^2$.

\item[Ex:  ]  Does the set of vectors
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
5\\
0
\end{bmatrix}, \begin{bmatrix}
5\\
-4
\end{bmatrix}\right\rbrace
\end{equation*}
%
span $\R^2$.

\textbf{Solution:  }  Again for a simple problem like this we can just take the determinant,
which happens to be $-20$, which is nonzero, therefore the vectors do span $\R^2$.

\item[Ex:  ]  Does the set of vectors
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
-2\\
5\\
0
\end{bmatrix}, \begin{bmatrix}
4\\
6\\
3
\end{bmatrix}\right\rbrace
\end{equation*}
%
span $\R^3$?

\textbf{Solution:  } $S$ does not span $\R^3$.  Not enough vectors, but it does span a plane.
If we wanted to show that it spans a plane we can't use our simple method anymore.  {\color{red}
Perhaps that might be a good midterm problem}.

\item[Ex:  ]  Is the set of vectors
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
-2\\
2
\end{bmatrix}, \begin{bmatrix}
3\\
5
\end{bmatrix}\right\rbrace
\end{equation*}
%
linearly independent or linearly dependent?

{\color{blue}The definition of linear independence I wrote down implies that if $c_1v_1+c_2v_2 = 0$
and we show $c_1=c_2=0$, then $v_1$ and $v_2$ are linearly independent, and if either $c_1,c_2 \neq 0$
then $v_1$ and $v_2$ are linearly dependent.}  {\color{red}This is usually how the definition is
written in linear algebra texts, but since I am a dynamicist, I decided to write it from the
functional perspective of differential equations.  They are equivalent though.}

\textbf{Solution:  }
These are linearly independent since
%
\begin{equation*}
c_1\begin{bmatrix}
-2\\
2
\end{bmatrix} + c_2\begin{bmatrix}
3\\
5
\end{bmatrix} = \begin{bmatrix}
-2c_1 + 3c_2\\
2c_1 + 5c_2
\end{bmatrix} = \begin{bmatrix}
0\\
0
\end{bmatrix} \Rightarrow c_2 = 2c_1/3 \text{  and  } c_2 = -2c_1/5 \Rightarrow c_1 = c_2 = 0.
\end{equation*}

\pagebreak

\item[Ex:  ]  Is the set of vectors
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
0\\
0
\end{bmatrix}, \begin{bmatrix}
1\\
-1
\end{bmatrix}\right\rbrace
\end{equation*}
%
linearly independent or linearly dependent?

\textbf{Solution:  }  They are linearly dependent since $c_1s_1 + c_2s_2 = c_2s_2$, so if
$c_2=0$, $c_1$ can be any real number.  Notice that any set that includes the origin (once
again my dynamics background is showing up.  In linear algebra this is usually called the
zero vector) is linearly dependent.
 
\end{enumerate}

\bigskip
\bigskip

Before we do some examples with bases, lets tap into our intuition.  Recall that from physics,
the ``standard basis'' for $\R^3$ are the unit vectors: $\hat{i}, \hat{j}, \hat{k}$.  We can
extend this to $\R^n$, where the standard basis will be
%
\begin{equation}
e_1 = \begin{bmatrix}
1\\
0\\
\vdots\\
\vdots\\
0
\end{bmatrix}, e_2 = \begin{bmatrix}
0\\
1\\
0\\
\vdots\\
0
\end{bmatrix}, \ldots e_n = \begin{bmatrix}
0\\
\vdots\\
\vdots\\
0\\
1
\end{bmatrix}.
\end{equation}
%
This is used all over Newtonian physics.  In Special and General Relativity quite different
bases are often used (e.g. Minkowski space, Schwarzchild space, etc).

Now lets do some examples with bases.  Recall that to prove a set of vectors is a basis, it needs
to be linearly independent and span the space.

\begin{enumerate}

\item[Ex:  ]  Why is
%
\begin{equation*}
S = \left\lbrace \begin{bmatrix}
-4\\
5
\end{bmatrix}, \begin{bmatrix}
0\\
0
\end{bmatrix}\right\rbrace
\end{equation*}
%
not a basis for $\R^2$?

\textbf{Solution:  }  The vectors are linearly dependent because of the zero vector.

\item[Ex:  ]  Why is
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
-3\\
2
\end{bmatrix}\right\rbrace
\end{equation*}
%
not a basis for $\R^2$?

\textbf{Solution:  }  Not enough vectors, and hence doesn't span the space.

\item[Ex:  ]  Why is
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
1\\
1\\
1
\end{bmatrix}, \begin{bmatrix}
0\\
1\\
1
\end{bmatrix}, \begin{bmatrix}
1\\
0\\
1
\end{bmatrix}, \begin{bmatrix}
0\\
0\\
0
\end{bmatrix}\right\rbrace
\end{equation*}
%
not a basis for $\R^3$

\textbf{Solution:  }  The vectors are linearly dependent.

\item[Ex:  ]  Show that
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
4\\
-3
\end{bmatrix}, \begin{bmatrix}
5\\
2
\end{bmatrix}\right\rbrace
\end{equation*}
%
is a basis for $\R^2$.

\textbf{Solution:  }

Lets first show linear independence:
%
\begin{equation*}
c_1\begin{bmatrix}
4\\
-3
\end{bmatrix} + c_2\begin{bmatrix}
5\\
2
\end{bmatrix} = \begin{bmatrix}
4c_1 + 5c_2\\
-3c_1 + 2c_2
\end{bmatrix} = \begin{bmatrix}
0\\
0
\end{bmatrix} \Rightarrow c_1 = -5c_2/4 \text{  and  } c_1 = 2c_2/3 \Rightarrow c_1 = c_2 = 0.
\checkmark
\end{equation*}
%

Now we show that the vectors span $\R^2$.
%
\begin{equation*}
\begin{bmatrix}
4c_1 + 5c_2\\
-3c_1 + 2c_2
\end{bmatrix} = \begin{bmatrix}
x\\
y
\end{bmatrix},
\end{equation*}
%
so lets take the determinant,
%
\begin{equation*}
\begin{vmatrix}
4 + 5\\
-3 + 2
\end{vmatrix} = 8 + 15 \neq 0. \checkmark
\end{equation*}

\pagebreak

\item[Ex:  ]  Show that
%
\begin{equation*}
S = \left\lbrace\begin{bmatrix}
1\\
5\\
3
\end{bmatrix}, \begin{bmatrix}
0\\
1\\
2
\end{bmatrix}, \begin{bmatrix}
0\\
0\\
6
\end{bmatrix}\right\rbrace
\end{equation*}
%
is a basis for $\R^3$.

\textbf{Solution:  }

Just like the previous problem we first show linear independence:
%
\begin{equation*}
c_1\begin{bmatrix}
1\\
5\\
3
\end{bmatrix} + c_2\begin{bmatrix}
0\\
1\\
2
\end{bmatrix} + c_3\begin{bmatrix}
0\\
0\\
6
\end{bmatrix} = \begin{bmatrix}
c_1\\
5c_1 + c_2\\
3c_1 + 2c_2 + 6c_3
\end{bmatrix} = \begin{bmatrix}
0\\
0\\
0
\end{bmatrix} \Rightarrow c_1 = c_2 = c_3 = 0. \checkmark
\end{equation*}

Then we show span by showing our coefficient matrix is nonsingular via the determinant:
%
\begin{equation*}
\begin{vmatrix}
1\\
5 + 1\\
3 + 2 + 6
\end{vmatrix} = 6 \neq 0. \checkmark
\end{equation*}

\end{enumerate}

\end{document}